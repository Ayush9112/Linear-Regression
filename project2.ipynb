{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484cbbbc",
   "metadata": {},
   "source": [
    "#### a. Using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "trainProject2.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hp\\python\\mlp2\\mlp2\\project2.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/python/mlp2/mlp2/project2.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/python/mlp2/mlp2/project2.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read datasets with comma as the delimiter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hp/python/mlp2/mlp2/project2.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(\u001b[39m'\u001b[39;49m\u001b[39mtrainProject2.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/python/mlp2/mlp2/project2.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(\u001b[39m'\u001b[39m\u001b[39mtestProject2.txt\u001b[39m\u001b[39m'\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/python/mlp2/mlp2/project2.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x_train \u001b[39m=\u001b[39m train_data[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:1813\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1813\u001b[0m     fid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[0;32m   1814\u001b[0m     fid_ctx \u001b[39m=\u001b[39m contextlib\u001b[39m.\u001b[39mclosing(fid)\n\u001b[0;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:532\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    530\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[0;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: trainProject2.txt not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read datasets with comma as the delimiter\n",
    "train_data = np.genfromtxt('trainProject2.txt', delimiter=',')\n",
    "test_data = np.genfromtxt('testProject2.txt', delimiter=',')\n",
    "\n",
    "x_train = train_data[:, 0]\n",
    "y_train = train_data[:, 1]\n",
    "\n",
    "x_test = test_data[:, 0]\n",
    "y_test = test_data[:, 1]\n",
    "\n",
    "def gen_features(x, k=0.5, d=3):\n",
    "    features = [np.ones_like(x)]\n",
    "    for i in range(1, d+1):\n",
    "        features.append(np.sin(i * k * x))\n",
    "    return np.vstack(features).T\n",
    "\n",
    "def fit_model(x_train, y_train, k=0.5, d=3):\n",
    "    X_train = gen_features(x_train, k, d)\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "models = [fit_model(x_train, y_train, k=0.5, d=d) for d in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cc7e4",
   "metadata": {},
   "source": [
    "#### b. Using only NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read datasets with comma as the delimiter\n",
    "train_data = np.genfromtxt('trainProject2.txt', delimiter=',')\n",
    "test_data = np.genfromtxt('testProject2.txt', delimiter=',')\n",
    "\n",
    "x_train = train_data[:, 0]\n",
    "y_train = train_data[:, 1]\n",
    "\n",
    "x_test = test_data[:, 0]\n",
    "y_test = test_data[:, 1]\n",
    "\n",
    "def gen_features(x, k=0.5, d=3):\n",
    "    features = [np.ones_like(x)]\n",
    "    for i in range(1, d+1):\n",
    "        features.append(np.sin(i * k * x))\n",
    "    return np.vstack(features).T\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return theta\n",
    "\n",
    "def fit_model(x_train, y_train, k=0.5, d=3):\n",
    "    X_train = gen_features(x_train, k, d)\n",
    "    theta = linear_regression(X_train, y_train)\n",
    "    return theta\n",
    "\n",
    "thetas = [fit_model(x_train, y_train, k=0.5, d=d) for d in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8989c",
   "metadata": {},
   "source": [
    "#### c. Plotting the Regression Learner's Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2668d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read datasets with comma as the delimiter\n",
    "train_data = np.genfromtxt('trainProject2.txt', delimiter=',')\n",
    "x_train = train_data[:, 0]\n",
    "y_train = train_data[:, 1]\n",
    "\n",
    "def gen_features(x, k=0.5, d=3):\n",
    "    features = [np.ones_like(x)]\n",
    "    for i in range(1, d+1):\n",
    "        features.append(np.sin(i * k * x))\n",
    "    return np.vstack(features).T\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return theta\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "def plot(x, y, k=0.5, d=3):\n",
    "    X = gen_features(x, k, d)\n",
    "    theta = linear_regression(X, y)\n",
    "    y_pred = predict(X, theta)\n",
    "    \n",
    "    # Sorting for plotting\n",
    "    sorted_indices = np.argsort(x)\n",
    "    \n",
    "    plt.scatter(x[sorted_indices], y[sorted_indices], color='blue', label='Data Points')\n",
    "    plt.plot(x[sorted_indices], y_pred[sorted_indices], color='red', label=f'Fit for d={d}')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Function Depth: {d}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for d in range(4):\n",
    "    plot(x_train, y_train, k=0.5, d=d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e85e4",
   "metadata": {},
   "source": [
    "#### d. Evaluating Regression Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9961d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read datasets with comma as the delimiter\n",
    "train_data = np.genfromtxt('trainProject2.txt', delimiter=',')\n",
    "test_data = np.genfromtxt('testProject2.txt', delimiter=',')\n",
    "\n",
    "x_train = train_data[:, 0]\n",
    "y_train = train_data[:, 1]\n",
    "x_test = test_data[:, 0]\n",
    "y_test = test_data[:, 1]\n",
    "\n",
    "def gen_features(x, k=0.5, d=3):\n",
    "    features = [np.ones_like(x)]\n",
    "    for i in range(1, d+1):\n",
    "        features.append(np.sin(i * k * x))\n",
    "    return np.vstack(features).T\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return theta\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "def compute_mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for d in range(4):\n",
    "    # Train on training data\n",
    "    X_train = gen_features(x_train, k=0.5, d=d)\n",
    "    theta = linear_regression(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    X_test = gen_features(x_test, k=0.5, d=d)\n",
    "    y_test_pred = predict(X_test, theta)\n",
    "    \n",
    "    # Compute the error\n",
    "    error = compute_mse(y_test, y_test_pred)\n",
    "    errors.append(error)\n",
    "\n",
    "# Plot the errors\n",
    "plt.figure()\n",
    "plt.plot(range(4), errors, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Function Depth (d)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Error vs. Function Depth')\n",
    "plt.xticks(range(4))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_d = np.argmin(errors)\n",
    "print(f\"The best function depth is d={best_d} with the minimum error of {errors[best_d]:.4f}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
